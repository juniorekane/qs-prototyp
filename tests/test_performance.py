import time
import pytest
from app import app

@pytest.fixture
def client():
    return app.test_client()

@pytest.mark.performance
def test_massive_ablesungen(client):
    start_time = time.time()
    erfolg_count = 0
    
    client.post("/zaehler/hinzufuegen", json={"gebaeude_id": "1", "typ": "Strom"})
    for i in range(100):  # Simuliere 1000 Ablesungen
        response = client.post("/ablesung/hinzufuegen", json={
            "gebaeude_id": "1",
            "zaehler_id": "1-2025-5487",
            "datum": "2025-03-01",
            "wert": 110 + i,
            "ableser": "Mieter"
        })
        if response.status_code == 201:
            erfolg_count += 1
        else:
            print(f"ğŸš¨ Fehler bei Ablesung {i}: {response.data.decode('utf-8')}")


    end_time = time.time()

    print("\nğŸš€ **Massisve Ablesung Ergebnis**")
    print(f"âœ… Erfolgreiche Ablesungen: {erfolg_count} / 1000")
    print(f"â³ Gesamtzeit: {end_time - start_time:.2f} Sekunden")
    print(f"âš¡ Durchschnittliche Zeit pro Ablesung: {(end_time - start_time) / 1000:.5f} Sekunden")
    assert erfolg_count == 100, f"Nicht alle Ablesungen wurden erfolgreich gespeichert!, {response.data.decode('utf-8'), erfolg_count}"

@pytest.mark.performance
def test_server_response_time(client):
    start_time = time.time()
    response = client.get("/")
    end_time = time.time()

    print("Ergebnis")
    print(f"{end_time - start_time:.2f}")
    
    assert response.status_code == 200
    assert (end_time - start_time) < 1, f"Antwortzeit zu hoch: {end_time - start_time:.2f}s"


@pytest.mark.performance
def test_massive_zaehler_erstellen(client):
    start_time = time.time()
    erfolg_count = 0

    for i in range(500):
        response = client.post("/zaehler/hinzufuegen", json={
            "gebaeude_id": f"{i}",
            "typ": "Strom"
        })

        if response.status_code == 201:
            erfolg_count += 1
        else:
            print(f"ğŸš¨ Fehler bei ZÃ¤hler {i}: {response.data.decode('utf-8')}")

    end_time = time.time()

    print("\nğŸš€ **Lasttest: 500 ZÃ¤hler hinzufÃ¼gen**")
    print(f"âœ… Erfolgreiche ZÃ¤hler: {erfolg_count} / 500")
    print(f"â³ Gesamtzeit: {end_time - start_time:.2f} Sekunden")
    print(f"âš¡ Durchschnittliche Zeit pro ZÃ¤hler: {(end_time - start_time) / 500:.5f} Sekunden")

    assert erfolg_count == 499, f"Nicht alle ZÃ¤hler wurden erfolgreich hinzugefÃ¼gt! : {response.data.decode('utf-8'), {erfolg_count}}"

@pytest.mark.performance
def test_massive_gebaeude_erstellen(client):
    start_time = time.time()
    erfolg_count = 0

    for i in range(100):
        response = client.post("/gebaeude/hinzufuegen", data={
            "name": f"Testhaus {i}",
            "adresse": f"TeststraÃŸe {i}",
            "eingang_anzahl": "2"
        })

        if response.status_code == 200:
            erfolg_count += 1
        else:
            print(f"ğŸš¨ Fehler bei GebÃ¤ude {i}: {response.data.decode('utf-8')}")

    end_time = time.time()

    print("\nğŸš€ **Lasttest: 100 GebÃ¤ude hinzufÃ¼gen**")
    print(f"âœ… Erfolgreiche GebÃ¤ude: {erfolg_count} / 100")
    print(f"â³ Gesamtzeit: {end_time - start_time:.2f} Sekunden")
    print(f"âš¡ Durchschnittliche Zeit pro GebÃ¤ude: {(end_time - start_time) / 100:.5f} Sekunden")

    assert erfolg_count == 100, f"Nicht alle GebÃ¤ude wurden erfolgreich gespeichert!, : {response.data.decode('utf-8')}"
